{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from keras.applications import vgg19\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set backend as tensorflow\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering(\"tf\")\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Start interactive session\n",
    "sess = tf.InteractiveSession()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'block1_conv1', u'block1_conv2', u'block1_pool', u'block2_conv1', u'block2_conv2', u'block2_pool', u'block3_conv1', u'block3_conv2', u'block3_conv3', u'block3_conv4', u'block3_pool', u'block4_conv1', u'block4_conv2', u'block4_conv3', u'block4_conv4', u'block4_pool', u'block5_conv1', u'block5_conv2', u'block5_conv3', u'block5_conv4', u'block5_pool', u'input_2']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File(\"vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\", \"r\")\n",
    "print(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLE_LAYERS = [\n",
    "    ('block1_conv1', 0.2),\n",
    "#     ('block1_conv2', 0.2),\n",
    "#     ('block2_conv1', 0.2),\n",
    "    ('block2_conv2', 0.2),\n",
    "#     ('block3_conv1', 0.2),\n",
    "#     ('block3_conv2', 0.2),\n",
    "#     ('block3_conv3', 0.2),\n",
    "    ('block3_conv2', 0.2),\n",
    "#     ('block4_conv1', 0.2),\n",
    "#     ('block4_conv2', 0.2),\n",
    "#     ('block4_conv3', 0.2),\n",
    "    ('block4_conv2', 0.2),\n",
    "#     ('block5_conv1', 0.2),\n",
    "#     ('block5_conv2', 0.2),\n",
    "#     ('block5_conv3', 0.2),\n",
    "    ('block5_conv2', 0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    IMAGE_WIDTH = 256\n",
    "    IMAGE_HEIGHT = 256\n",
    "    COLOR_CHANNELS = 3\n",
    "    CONTENT_WEIGHT = 0.025\n",
    "    STYLE_WEIGHT = 5.0\n",
    "    TOTAL_VARIATION_WEIGHT = 1.0\n",
    "    NOISE_RATIO = 0.6\n",
    "    MEANS = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_and_normalize_image(image_path):\n",
    "    \"\"\"\n",
    "    Reshape and normalize the input image (content or style)\n",
    "    \"\"\"\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((CONFIG.IMAGE_WIDTH, CONFIG.IMAGE_HEIGHT))\n",
    "    \n",
    "    image_array = np.asarray(image, dtype='float32')\n",
    "    image = np.expand_dims(image_array, axis=0)\n",
    "    \n",
    "    # Substract the mean to match the expected input of VGG16\n",
    "    image = image - CONFIG.MEANS\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise_image(content_image, noise_ratio = CONFIG.NOISE_RATIO):\n",
    "    \"\"\"\n",
    "    Generates a noisy image by adding random noise to the content_image\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate a random noise_image\n",
    "    noise_image = np.random.uniform(-20, 20, (1, CONFIG.IMAGE_HEIGHT, CONFIG.IMAGE_WIDTH,\n",
    "                                              CONFIG.COLOR_CHANNELS)).astype('float32')\n",
    "    \n",
    "    # Set the input_image to be a weighted average of the content_image and a noise_image\n",
    "    input_image = noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
    "    \n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_content_loss(content, generated):\n",
    "    m, n_H, n_W, n_C = generated.get_shape().as_list()\n",
    "\n",
    "    content = tf.reshape(content, [-1])\n",
    "    generated = tf.reshape(generated, [-1])\n",
    "\n",
    "    return tf.reduce_sum(tf.reduce_sum(tf.square(tf.subtract(content, generated)))) /\\\n",
    "                        (4*n_H*n_W*n_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    gram = tf.matmul(x, x, transpose_b=True)\n",
    "    return gram\n",
    "\n",
    "def style_layer_loss(style, generated):\n",
    "    m, n_H, n_W, n_C = generated.get_shape().as_list()\n",
    "    \n",
    "    style = tf.reshape(tf.transpose(style), (n_C, -1))\n",
    "    generated = tf.reshape(tf.transpose(generated), (n_C, -1))\n",
    "    \n",
    "    S = gram_matrix(style)\n",
    "    G = gram_matrix(generated)\n",
    "\n",
    "    channels = n_C\n",
    "    size = n_H*n_W\n",
    "\n",
    "    return tf.divide(tf.reduce_sum(tf.reduce_sum(tf.square(tf.subtract(S, G)))),\n",
    "                     (4. * (channels ** 2) * (size ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get content_image from file\n",
    "content_image_path = \"./images/louvre_small.jpg\"\n",
    "content_image = reshape_and_normalize_image(content_image_path)\n",
    "\n",
    "image_to_show = plt.imread(content_image_path)\n",
    "# plt.imshow(image_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_image_path = \"./images/monet.jpg\"\n",
    "style_image = reshape_and_normalize_image(style_image_path)\n",
    "\n",
    "image_to_show = plt.imread(content_image_path)\n",
    "# plt.imshow(image_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random noise_image\n",
    "generated_image = generate_noise_image(content_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined input for model\n",
    "# input_tensor = K.concatenate([content_image,\n",
    "#                           style_image,\n",
    "#                           generated_image], axis=0)\n",
    "\n",
    "input_tensor = tf.Variable(np.zeros((1, CONFIG.IMAGE_HEIGHT, CONFIG.IMAGE_WIDTH, CONFIG.COLOR_CHANNELS)),\n",
    "                           dtype='float32', name=\"input_tensor\")\n",
    "model = vgg19.VGG19(weights=None,\n",
    "                    input_tensor=input_tensor,\n",
    "                    include_top=False)\n",
    "model.load_weights(\"vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "outputs_list = [(layer_name, model.get_layer(layer_name).output)\n",
    "                     for layer_name, _ in STYLE_LAYERS]\n",
    "\n",
    "# layer_outputs = [output_tensors for _, output_tensors in outputs_list]\n",
    "# print(layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_model = Model(inputs=model.input, outputs=layer_outputs)\n",
    "# content_model.load_weights(\"vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(content_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_input = model.get_layer(\"input_1\").output\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "<type 'numpy.ndarray'> (1, 32, 32, 512)\n"
     ]
    }
   ],
   "source": [
    "# loss for content image\n",
    "\n",
    "# Assign the input of the model to be the \"content\" image \n",
    "sess.run(input_tensor.assign(content_image))\n",
    "\n",
    "content_loss = 0.\n",
    "out = model.get_layer(outputs_list[-2][0]).output\n",
    "content_features = sess.run(out)\n",
    "generated_features = out\n",
    "content_loss = compute_content_loss(content_features, generated_features)\n",
    "\n",
    "print(content_loss.eval())\n",
    "\n",
    "print(type(content_features), content_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss for style image\n",
    "def compute_style_loss(model, STYLE_LAYERS):\n",
    "    loss = 0.\n",
    "    for layer_name, coeff in STYLE_LAYERS:\n",
    "        # Select the output tensor of the currently selected layer\n",
    "        out = model.get_layer(layer_name).output\n",
    "        style_features = sess.run(out)        \n",
    "        generated_features = out\n",
    "        \n",
    "        print(style_features.shape)\n",
    "        print(generated_features.shape)\n",
    "        \n",
    "        sl = style_layer_loss(style_features, generated_features)\n",
    "        loss += coeff * sl\n",
    "        \n",
    "#         print(loss.eval())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 64)\n",
      "(1, 256, 256, 64)\n",
      "(1, 128, 128, 128)\n",
      "(1, 128, 128, 128)\n",
      "(1, 64, 64, 256)\n",
      "(1, 64, 64, 256)\n",
      "(1, 32, 32, 512)\n",
      "(1, 32, 32, 512)\n",
      "(1, 16, 16, 512)\n",
      "(1, 16, 16, 512)\n"
     ]
    }
   ],
   "source": [
    "# Assign the input of the model to be the \"style\" image \n",
    "sess.run(input_tensor.assign(style_image))\n",
    "\n",
    "style_loss = compute_style_loss(model, STYLE_LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_loss(content_loss, style_loss, alpha=10, beta=40):\n",
    "    return (content_loss*alpha) + (style_loss*beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = total_loss(content_loss, style_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "optimizer = tf.train.AdamOptimizer(5.0)\n",
    "\n",
    "# define train_step\n",
    "train_step = optimizer.minimize(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(path, image):\n",
    "    \n",
    "    # Un-normalize the image so that it looks good\n",
    "    image = image + CONFIG.MEANS\n",
    "    \n",
    "    # Clip and Save the image\n",
    "    image = np.clip(image[0], 0, 255).astype('uint8')\n",
    "    scipy.misc.imsave(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_nn(sess, input_image, num_iterations = 1):\n",
    "    \n",
    "    # Initialize global variables (you need to run the session on the initializer)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Assign the input of the model to be the \"input\" image \n",
    "    sess.run(input_tensor.assign(input_image))\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        # Run the session on the train_step to minimize the total cost\n",
    "        sess.run([train_step])\n",
    "        \n",
    "        # Compute the generated image by running the session on the current model['input']\n",
    "        generated_image = sess.run(input_tensor)\n",
    "        \n",
    "        print(generated_image.shape)\n",
    "\n",
    "        # Print every 20 iteration.\n",
    "        if i%1 == 0:\n",
    "            Jt, Jc, Js = sess.run([J, content_loss, style_loss])\n",
    "            print(\"Iteration \" + str(i) + \" :\")\n",
    "            print(\"content cost = \", Jc)\n",
    "            print(\"style cost = \", Js)\n",
    "            print(\"total cost = \", Jt)\n",
    "            \n",
    "            # save current generated image in the \"/output\" directory\n",
    "            save_image(\"output/\" + str(i) + \".png\", generated_image)\n",
    "\n",
    "    # save last generated image\n",
    "    save_image('output/generated_image.jpg', generated_image)\n",
    "    \n",
    "    return generated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 3)\n",
      "Iteration 0 :\n",
      "content cost =  inf\n",
      "style cost =  nan\n",
      "total cost =  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/envs/coreml/lib/python2.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "out = model_nn(sess, generated_image)\n",
    "\n",
    "# print(generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
