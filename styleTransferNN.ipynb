{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from keras.applications import vgg19\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set backend as tensorflow\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering(\"tf\")\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Start interactive session\n",
    "sess = tf.InteractiveSession()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'block1_conv1', u'block1_conv2', u'block1_pool', u'block2_conv1', u'block2_conv2', u'block2_pool', u'block3_conv1', u'block3_conv2', u'block3_conv3', u'block3_conv4', u'block3_pool', u'block4_conv1', u'block4_conv2', u'block4_conv3', u'block4_conv4', u'block4_pool', u'block5_conv1', u'block5_conv2', u'block5_conv3', u'block5_conv4', u'block5_pool', u'input_2']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File(\"vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\", \"r\")\n",
    "print(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STYLE_LAYERS = [\n",
    "    ('block1_conv1', 0.2),\n",
    "#     ('block1_conv2', 0.2),\n",
    "#     ('block2_conv1', 0.2),\n",
    "    ('block2_conv2', 0.2),\n",
    "#     ('block3_conv1', 0.2),\n",
    "#     ('block3_conv2', 0.2),\n",
    "#     ('block3_conv3', 0.2),\n",
    "    ('block3_conv4', 0.2),\n",
    "#     ('block4_conv1', 0.2),\n",
    "#     ('block4_conv2', 0.2),\n",
    "#     ('block4_conv3', 0.2),\n",
    "    ('block4_conv4', 0.2),\n",
    "#     ('block5_conv1', 0.2),\n",
    "#     ('block5_conv2', 0.2),\n",
    "#     ('block5_conv3', 0.2),\n",
    "    ('block5_conv4', 0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    IMAGE_WIDTH = 256\n",
    "    IMAGE_HEIGHT = 256\n",
    "    COLOR_CHANNELS = 3\n",
    "    CONTENT_WEIGHT = 0.025\n",
    "    STYLE_WEIGHT = 5.0\n",
    "    TOTAL_VARIATION_WEIGHT = 1.0\n",
    "    NOISE = 0.6\n",
    "    MEANS = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_and_normalize_image(image_path):\n",
    "    \"\"\"\n",
    "    Reshape and normalize the input image (content or style)\n",
    "    \"\"\"\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((CONFIG.IMAGE_WIDTH, CONFIG.IMAGE_HEIGHT))\n",
    "    \n",
    "    image_array = np.asarray(image, dtype='float32')\n",
    "    image = np.expand_dims(image_array, axis=0)\n",
    "    \n",
    "    # Substract the mean to match the expected input of VGG16\n",
    "    image = image - CONFIG.MEANS\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_content_loss(content, generated):\n",
    "    m, n_H, n_W, n_C = generated.get_shape().as_list()\n",
    "\n",
    "    content = tf.reshape(content, [-1])\n",
    "    generated = tf.reshape(generated, [-1])\n",
    "\n",
    "    return tf.reduce_sum(tf.reduce_sum(tf.square(tf.subtract(generated, content)))) /\\\n",
    "                        (4*n_H*n_W*n_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    gram = tf.matmul(x, x, transpose_b=True)\n",
    "    return gram\n",
    "\n",
    "def style_layer_loss(style, generated):\n",
    "    m, n_H, n_W, n_C = generated.get_shape().as_list()\n",
    "    \n",
    "    style = tf.reshape(tf.transpose(style), (n_C, -1))\n",
    "    generated = tf.reshape(tf.transpose(generated), (n_C, -1))\n",
    "    \n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(generated)\n",
    "    channels = n_C\n",
    "    size = n_H*n_W\n",
    "\n",
    "    return tf.reduce_sum(tf.square(tf.subtract(S, C))) \\\n",
    "            / (4. * (channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get content_image from file\n",
    "content_image_path = \"./images/louvre_small.jpg\"\n",
    "content_image = reshape_and_normalize_image(content_image_path)\n",
    "\n",
    "image_to_show = plt.imread(content_image_path)\n",
    "# plt.imshow(image_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "style_image_path = \"./images/monet.jpg\"\n",
    "style_image = reshape_and_normalize_image(style_image_path)\n",
    "\n",
    "image_to_show = plt.imread(content_image_path)\n",
    "# plt.imshow(image_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a random noise_image\n",
    "generated_image = np.random.uniform(-20, 20, (1, CONFIG.IMAGE_HEIGHT,\n",
    "                                              CONFIG.IMAGE_WIDTH,\n",
    "                                              CONFIG.COLOR_CHANNELS)).astype('float32')\n",
    "\n",
    "# Set the input_image to be a weighted average of the content_image and a noise_image\n",
    "generated_image = generated_image * CONFIG.NOISE + content_image * (1 - CONFIG.NOISE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combined input for model\n",
    "# input_tensor = K.concatenate([content_image,\n",
    "#                           style_image,\n",
    "#                           generated_image], axis=0)\n",
    "\n",
    "input_tensor = tf.Variable(content_image, expected_shape=(1,300,400,3))\n",
    "model = vgg19.VGG19(weights=None,\n",
    "                    input_tensor=input_tensor,\n",
    "                    include_top=False)\n",
    "# model.load_weights(\"vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "outputs_list = [(layer_name, model.get_layer(layer_name).output) \\\n",
    "                     for layer_name, _ in STYLE_LAYERS]\n",
    "\n",
    "layer_outputs = [output_tensors for _, output_tensors in outputs_list]\n",
    "# print(layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_input = model.get_layer(\"input_1\").output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_model = Model(inputs=model.input, outputs=layer_outputs)\n",
    "content_model.load_weights(\"vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(content_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# layer_outputs_content = model.predict(content_image)\n",
    "# layer_outputs_style = model.predict(style_image)\n",
    "# layer_outputs_generated = model.predict(generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[   0.          499.9258728     0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.           63.74557114    0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   ..., \n",
      "   [   0.           63.13259125    0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]]\n",
      "\n",
      "  [[   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   ..., \n",
      "   [ 257.60629272  199.37548828    0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [ 604.40631104  137.88998413    0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [ 419.58029175   49.29804611    0.         ...,    0.            0.\n",
      "       0.        ]]\n",
      "\n",
      "  [[   0.            0.          272.97320557 ...,    0.            0.\n",
      "     226.07118225]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.          640.05474854 ...,    0.            0.\n",
      "       0.        ]\n",
      "   ..., \n",
      "   [ 243.77397156    0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [ 441.77523804    0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [ 208.24847412    0.            0.         ...,    0.            0.\n",
      "       0.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[   0.           59.09178162    0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,  264.45620728    0.\n",
      "       0.        ]\n",
      "   ..., \n",
      "   [  19.20789528    0.            0.         ...,  147.49380493\n",
      "      44.17846298    0.        ]\n",
      "   [ 346.35037231    0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [  79.78527832    0.            0.         ...,    0.            0.\n",
      "       0.        ]]\n",
      "\n",
      "  [[   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   ..., \n",
      "   [   0.            0.            0.         ...,    0.          257.97137451\n",
      "       0.        ]\n",
      "   [ 163.78929138    0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]]\n",
      "\n",
      "  [[   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   ..., \n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [ 107.45096588    0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]]]]\n",
      "<type 'numpy.ndarray'> (1, 32, 32, 512)\n",
      "Tensor(\"block4_conv4/Relu:0\", shape=(1, 32, 32, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# loss for content image\n",
    "sess.run(model_input.assign(conten   t_image))\n",
    "\n",
    "content_loss = 0.\n",
    "content_features = sess.run(outputs_list[-2][1])\n",
    "generated_features = outputs_list[-2][1]\n",
    "content_loss = compute_content_loss(content_features, generated_features)\n",
    "\n",
    "print(content_features)\n",
    "print(type(content_features), content_features.shape)\n",
    "print(generated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss for style image\n",
    "def compute_style_loss():\n",
    "    # get the count of style layers\n",
    "    count = len(STYLE_LAYERS)\n",
    "    \n",
    "    loss = 0.\n",
    "    for layer_name, coeff in STYLE_LAYERS:\n",
    "        # Select the output tensor of the currently selected layer\n",
    "        out = outputs_list[-count][1]\n",
    "\n",
    "        style_features = sess.run(out)\n",
    "        generated_features = out\n",
    "        sl = style_layer_loss(style_features, generated_features)\n",
    "        loss += coeff * sl\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(model_input.assign(style_image))\n",
    "style_loss = compute_style_loss()\n",
    "\n",
    "# print(style_loss.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def total_loss(content_loss, style_loss, alpha=10, beta=40):\n",
    "    return (content_loss*alpha) + (style_loss*beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103546.0\n"
     ]
    }
   ],
   "source": [
    "J = total_loss(content_loss, style_loss)\n",
    "print(J.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "optimizer = tf.train.AdamOptimizer(2.0)\n",
    "\n",
    "# define train_step\n",
    "train_step = optimizer.minimize(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_image(path, image):\n",
    "    \n",
    "    # Un-normalize the image so that it looks good\n",
    "    image = image + CONFIG.MEANS\n",
    "    \n",
    "    # Clip and Save the image\n",
    "    image = np.clip(image[0], 0, 255).astype('uint8')\n",
    "    scipy.misc.imsave(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_nn(sess, input_image, num_iterations = 3):\n",
    "    \n",
    "    # Initialize global variables (you need to run the session on the initializer)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    sess.run(model_input.assign(input_image))\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        # Run the session on the train_step to minimize the total cost\n",
    "        sess.run([train_step])\n",
    "        \n",
    "        # Compute the generated image by running the session on the current model['input']\n",
    "        generated_image = sess.run(model_input)\n",
    "\n",
    "        print(generated_image.shape)\n",
    "\n",
    "        # Print every 20 iteration.\n",
    "        if i%1 == 0:\n",
    "            Jt, Jc, Js = sess.run([J, content_loss, style_loss])\n",
    "            print(\"Iteration \" + str(i) + \" :\")\n",
    "            print(\"total cost = \" + str(Jt))\n",
    "            print(\"content cost = \" + str(Jc))\n",
    "            print(\"style cost = \" + str(Js))\n",
    "            \n",
    "            # save current generated image in the \"/output\" directory\n",
    "            save_image(\"output/\" + str(i) + \".png\", generated_image)\n",
    "    \n",
    "    # save last generated image\n",
    "    save_image('output/generated_image.jpg', generated_image)\n",
    "    \n",
    "    return generated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 3)\n",
      "Iteration 0 :\n",
      "total cost = inf\n",
      "content cost = inf\n",
      "style cost = 3.06153e+10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harshbhardwaj/anaconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 3)\n",
      "Iteration 1 :\n",
      "total cost = nan\n",
      "content cost = nan\n",
      "style cost = nan\n",
      "(1, 256, 256, 3)\n",
      "Iteration 2 :\n",
      "total cost = nan\n",
      "content cost = nan\n",
      "style cost = nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan]],\n",
       "\n",
       "        ..., \n",
       "        [[ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan]],\n",
       "\n",
       "        [[ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan],\n",
       "         ..., \n",
       "         [ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan],\n",
       "         [ nan,  nan,  nan]]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nn(sess, generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
