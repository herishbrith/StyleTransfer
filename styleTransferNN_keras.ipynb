{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "import scipy as sc\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "from scipy.optimize import fmin_cg\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.applications import vgg19\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    IMAGE_WIDTH = 400\n",
    "    IMAGE_HEIGHT = 300\n",
    "    COLOR_CHANNELS = 3\n",
    "    CONTENT_WEIGHT = 5\n",
    "    STYLE_WEIGHT = 100\n",
    "    TOTAL_VARIATION_WEIGHT = 1.\n",
    "    NOISE_RATIO = .6\n",
    "    MEANS = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (1,\n",
    "                CONFIG.IMAGE_HEIGHT,\n",
    "                CONFIG.IMAGE_WIDTH,\n",
    "                CONFIG.COLOR_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STYLE_LAYERS = [\n",
    "    ('block1_conv1', .5),\n",
    "#     ('block1_conv2', .2),\n",
    "    ('block2_conv1', .5),\n",
    "#     ('block2_conv2', .2),\n",
    "    ('block3_conv1', .5),\n",
    "#     ('block3_conv2', 0.2),\n",
    "#     ('block3_conv3', .2),\n",
    "#     ('block3_conv4', 0.2),\n",
    "    ('block4_conv1', .5),\n",
    "#     ('block4_conv2', 0.2),\n",
    "#     ('block4_conv3', 0.2),\n",
    "#     ('block4_conv4', .2),\n",
    "    ('block5_conv1', .5),\n",
    "#     ('block5_conv2', 0.2),\n",
    "#     ('block5_conv3', 0.2),\n",
    "#     ('block5_conv4', .2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_and_normalize_image(image_path):\n",
    "    \"\"\"\n",
    "    Reshape and normalize the input image (content or style)\n",
    "    \"\"\"\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((CONFIG.IMAGE_WIDTH, CONFIG.IMAGE_HEIGHT))\n",
    "    \n",
    "    image_array = np.asarray(image, dtype='float32')\n",
    "    image = np.expand_dims(image_array, axis=0)\n",
    "    \n",
    "    # Substract the mean to match the expected input of VGG16\n",
    "    image = image - CONFIG.MEANS\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_content_loss(content, generated):\n",
    "    n_H, n_W, n_C = generated.get_shape().as_list()\n",
    "\n",
    "    content = K.reshape(content, [-1])\n",
    "    generated = K.reshape(generated, [-1])\n",
    "\n",
    "    return K.sum(K.square(content - generated)) / (4*n_H*n_W*n_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    gram = K.dot(x, K.transpose(x))\n",
    "    return gram\n",
    "\n",
    "def style_layer_loss(style, generated):\n",
    "    n_H, n_W, n_C = generated.get_shape().as_list()\n",
    "    \n",
    "    style = K.reshape(style, (n_C, n_H*n_W))\n",
    "    generated = K.reshape(generated, (n_C, n_H*n_W))\n",
    "    \n",
    "    S = gram_matrix(style)\n",
    "    G = gram_matrix(generated)\n",
    "\n",
    "    channels = n_C\n",
    "    size = n_H*n_W\n",
    "\n",
    "    return K.sum(K.square(S - G)) / (4. * (channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_image(path, image):\n",
    "    \n",
    "    # Un-normalize the image so that it looks good\n",
    "    image = image + CONFIG.MEANS\n",
    "    \n",
    "    # Clip and Save the image\n",
    "    image = np.clip(image[0], 0, 255).astype('uint8')\n",
    "    scipy.misc.imsave(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_image_path = \"./images/louvre_small.jpg\"\n",
    "content_image = K.variable(reshape_and_normalize_image(content_image_path))\n",
    "\n",
    "style_image_path = \"./images/monet.jpg\"\n",
    "style_image = K.variable(reshape_and_normalize_image(style_image_path))\n",
    "\n",
    "generated_image = K.placeholder(IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine the 3 images into a single Keras tensor\n",
    "input_image = K.concatenate([content_image,\n",
    "                            style_image,\n",
    "                            generated_image], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = vgg19.VGG19(weights=None, input_tensor=input_image, include_top=False)\n",
    "model.load_weights(\"./vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract features only from the content layer\n",
    "features = outputs_dict[\"block4_conv2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_features = features[0,:,:,:]\n",
    "generated_features = features[2,:,:,:]\n",
    "\n",
    "content_loss = compute_content_loss(content_features, generated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "style_loss = K.variable(0.0)\n",
    "\n",
    "for layer_name, coeff in STYLE_LAYERS:\n",
    "    features = outputs_dict[layer_name]\n",
    "    style_features = features[1,:,:,:]\n",
    "    generated_features = features[2,:,:,:]\n",
    "    style_loss += coeff * style_layer_loss(style_features, generated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_loss = content_loss + style_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute gradients of output img with respect to loss\n",
    "grads = K.gradients(total_loss, generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = [total_loss]\n",
    "outputs += grads\n",
    "loss_grads_function = K.function([generated_image], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "\n",
    "    def calculate_loss_grads(self, x):\n",
    "        self.out = loss_grads_function([x])\n",
    "\n",
    "    def get_loss(self, x):\n",
    "        x = x.reshape(IMAGE_SHAPE)\n",
    "        self.out = loss_grads_function([x])\n",
    "        return self.out[0]\n",
    "\n",
    "    def get_grads(self, x):\n",
    "        x = x.reshape(IMAGE_SHAPE)\n",
    "        self.out = loss_grads_function([x])\n",
    "        print(self.out[1].shape)\n",
    "        return np.array(self.out[1]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = np.random.uniform(0, 255, IMAGE_SHAPE) - 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluator = Evaluator()\n",
    "evaluator.calculate_loss_grads(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300, 400, 3)\n",
      "(1, 300, 400, 3)\n",
      "(1, 300, 400, 3)\n",
      "(1, 300, 400, 3)\n",
      "(1, 300, 400, 3)\n",
      "(1, 300, 400, 3)\n",
      "(1, 300, 400, 3)\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 1716788608.000000\n",
      "         Iterations: 1\n",
      "         Function evaluations: 7\n",
      "         Gradient evaluations: 7\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-a5060604265b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                            \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                            \u001b[0mfprime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_grads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                            maxiter=1)\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack"
     ]
    }
   ],
   "source": [
    "y, min_val, info = fmin_cg(evaluator.get_loss,\n",
    "                           x.flatten(),\n",
    "                           fprime=evaluator.get_grads,\n",
    "                           maxiter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-9be490b47037>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# imarray = np.random.rand(1080, 1080, 3) * 255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./output/result_image.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "# imarray = np.random.rand(1080, 1080, 3) * 255\n",
    "im = Image.fromarray(y.astype('uint8'))\n",
    "im.save('./output/result_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_and_normalize_image(image_path):\n",
    "    \"\"\"\n",
    "    Reshape and normalize the input image (content or style)\n",
    "    \"\"\"\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((338, 254))\n",
    "    \n",
    "    image_array = np.asarray(image, dtype='float32')\n",
    "    image = np.expand_dims(image_array, axis=0)\n",
    "    \n",
    "    # Substract the mean to match the expected input of VGG16\n",
    "    image = image - np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_noise_image(content_image, noise_ratio = 0.6):\n",
    "    \"\"\"\n",
    "    Generates a noisy image by adding random noise to the content_image\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate a random noise_image\n",
    "    noise_image = np.random.uniform(-10, 10, (1, 254, 338, 3)).astype('float32')\n",
    "    \n",
    "    # Set the input_image to be a weighted average of the content_image and a noise_image\n",
    "    input_image = noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
    "    \n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_image = reshape_and_normalize_image(\"dog.jpg\")\n",
    "generated_image = generate_noise_image(content_image)\n",
    "\n",
    "im = Image.fromarray(generated_image[0].astype('uint8'))\n",
    "im.save('generated_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
