{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.applications import vgg19\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    IMAGE_WIDTH = 400\n",
    "    IMAGE_HEIGHT = 300\n",
    "    COLOR_CHANNELS = 3\n",
    "    CONTENT_WEIGHT = 5\n",
    "    STYLE_WEIGHT = 100\n",
    "    TOTAL_VARIATION_WEIGHT = 1.\n",
    "    NOISE_RATIO = .6\n",
    "    MEANS = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLE_LAYERS = [\n",
    "    ('conv1_1', .5),\n",
    "#     ('conv1_2', .2),\n",
    "    ('conv2_1', .5),\n",
    "#     ('conv2_2', .2),\n",
    "    ('conv3_1', .5),\n",
    "#     ('conv3_2', 0.2),\n",
    "#     ('conv3_3', .2),\n",
    "#     ('conv3_4', 0.2),\n",
    "    ('conv4_1', .5),\n",
    "#     ('conv4_2', 0.2),\n",
    "#     ('conv4_3', 0.2),\n",
    "#     ('conv4_4', .2),\n",
    "    ('conv5_1', .5),\n",
    "#     ('conv5_2', 0.2),\n",
    "#     ('conv5_3', 0.2),\n",
    "#     ('conv5_4', .2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_and_normalize_image(image_path):\n",
    "    \"\"\"\n",
    "    Reshape and normalize the input image (content or style)\n",
    "    \"\"\"\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((CONFIG.IMAGE_WIDTH, CONFIG.IMAGE_HEIGHT))\n",
    "    \n",
    "    image_array = np.asarray(image, dtype='float32')\n",
    "    image = np.expand_dims(image_array, axis=0)\n",
    "    \n",
    "    # Substract the mean to match the expected input of VGG16\n",
    "    image = image - CONFIG.MEANS\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise_image(content_image, noise_ratio = CONFIG.NOISE_RATIO):\n",
    "    \"\"\"\n",
    "    Generates a noisy image by adding random noise to the content_image\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate a random noise_image\n",
    "    noise_image = np.random.uniform(-20, 20, (1, CONFIG.IMAGE_HEIGHT, CONFIG.IMAGE_WIDTH,\n",
    "                                              CONFIG.COLOR_CHANNELS)).astype('float32')\n",
    "    \n",
    "    # Set the input_image to be a weighted average of the content_image and a noise_image\n",
    "    input_image = noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
    "    \n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image_path = \"./images/louvre_small.jpg\"\n",
    "content_image = reshape_and_normalize_image(content_image_path)\n",
    "\n",
    "style_image_path = \"./images/monet.jpg\"\n",
    "style_image = reshape_and_normalize_image(style_image_path)\n",
    "\n",
    "generated_image = generate_noise_image(content_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_content_loss(content, generated):\n",
    "    m, n_H, n_W, n_C = generated.shape\n",
    "\n",
    "    content = np.reshape(content, [-1])\n",
    "    generated = np.reshape(generated, [-1])\n",
    "\n",
    "    return np.sum(np.square(content - generated)) / (4*n_H*n_W*n_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    gram = np.dot(np.transpose(x), x)\n",
    "    return gram\n",
    "\n",
    "def style_layer_loss(style, generated):\n",
    "    m, n_H, n_W, n_C = generated.shape\n",
    "    \n",
    "    style = np.reshape(style, (n_H*n_W, n_C))\n",
    "    generated = np.reshape(generated, (n_H*n_W, n_C))\n",
    "    \n",
    "    S = gram_matrix(style)\n",
    "    G = gram_matrix(generated)\n",
    "\n",
    "    channels = n_C\n",
    "    size = n_H*n_W\n",
    "\n",
    "    return np.sum(np.square(S - G)) / (4. * (channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_loss(sess, alpha=20, beta=40):\n",
    "\n",
    "    # Assign the input of the model to be the \"content\" image \n",
    "    sess.run(model[\"input\"].assign(content_image))\n",
    "\n",
    "    # Get content loss from output of block 4, layer 2\n",
    "    out = model[\"conv4_2\"]\n",
    "    content_features = sess.run(out)\n",
    "    generated_features = out\n",
    "    content_loss = compute_content_loss(content_features, generated_features)\n",
    "    \n",
    "    # loss for style image\n",
    "    style_loss = 0.\n",
    "    \n",
    "    # Assign the input of the model to be the \"style\" image \n",
    "    sess.run(model[\"input\"].assign(style_image))\n",
    "    \n",
    "    for layer_name, coeff in STYLE_LAYERS:\n",
    "        # Select the output tensor of the currently selected layer\n",
    "        out = model[layer_name]\n",
    "        style_features = sess.run(out)\n",
    "        generated_features = out\n",
    "        style_loss += coeff * style_layer_loss(style_features, generated_features)\n",
    "    \n",
    "    # Get total loss using alpha and beta\n",
    "    total_loss = (content_loss*alpha) + (style_loss*beta)\n",
    "    \n",
    "    return content_loss, style_loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined input for model\n",
    "input_tensor = tf.Variable(np.zeros((1,\n",
    "                                     CONFIG.IMAGE_HEIGHT,\n",
    "                                     CONFIG.IMAGE_WIDTH,\n",
    "                                     CONFIG.COLOR_CHANNELS)),\n",
    "                           dtype='float32', name=\"input_tensor\")\n",
    "input_tensor = Input(tensor=input_tensor)\n",
    "\n",
    "model = vgg19.VGG19(weights=None,\n",
    "                    input_tensor=input_tensor,\n",
    "                    include_top=False)\n",
    "model.load_weights(\"./vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer vgg19 was called with an input that isn't a symbolic tensor. Received type: <type 'numpy.ndarray'>. Full input: [array([[[[-98.68 , -56.779,  12.061],\n         [-97.68 , -55.779,  13.061],\n         [-97.68 , -54.779,  16.061],\n         ..., \n         [-99.68 , -68.779,  -9.939],\n         [-98.68 , -69.779,  -9.939],\n         [-98.68 , -69.779,  -9.939]],\n\n        [[-98.68 , -56.779,  12.061],\n         [-97.68 , -55.779,  13.061],\n         [-97.68 , -54.779,  16.061],\n         ..., \n         [-99.68 , -68.779,  -9.939],\n         [-98.68 , -69.779,  -9.939],\n         [-98.68 , -69.779,  -9.939]],\n\n        [[-97.68 , -55.779,  13.061],\n         [-96.68 , -54.779,  14.061],\n         [-96.68 , -53.779,  17.061],\n         ..., \n         [-98.68 , -67.779,  -8.939],\n         [-97.68 , -68.779,  -8.939],\n         [-98.68 , -69.779,  -9.939]],\n\n        ..., \n        [[-60.68 , -57.779, -55.939],\n         [-59.68 , -56.779, -54.939],\n         [-60.68 , -57.779, -55.939],\n         ..., \n         [-70.68 , -67.779, -57.939],\n         [-68.68 , -66.779, -56.939],\n         [-67.68 , -65.779, -55.939]],\n\n        [[-37.68 , -32.779, -31.939],\n         [-32.68 , -27.779, -26.939],\n         [-31.68 , -26.779, -25.939],\n         ..., \n         [-72.68 , -69.779, -59.939],\n         [-72.68 , -70.779, -61.939],\n         [-72.68 , -70.779, -61.939]],\n\n        [[-23.68 , -18.779, -17.939],\n         [-24.68 , -19.779, -18.939],\n         [-36.68 , -31.779, -30.939],\n         ..., \n         [-73.68 , -69.779, -61.939],\n         [-74.68 , -72.779, -63.939],\n         [-76.68 , -74.779, -65.939]]]])]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-01514d8c1aae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/apple/anaconda3/envs/coreml/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0;31m# with the input_spec set at build time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/apple/anaconda3/envs/coreml/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    430\u001b[0m                                  \u001b[0;34m'Received type: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full input: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. All inputs to the layer '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m                                  'should be tensors.')\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer vgg19 was called with an input that isn't a symbolic tensor. Received type: <type 'numpy.ndarray'>. Full input: [array([[[[-98.68 , -56.779,  12.061],\n         [-97.68 , -55.779,  13.061],\n         [-97.68 , -54.779,  16.061],\n         ..., \n         [-99.68 , -68.779,  -9.939],\n         [-98.68 , -69.779,  -9.939],\n         [-98.68 , -69.779,  -9.939]],\n\n        [[-98.68 , -56.779,  12.061],\n         [-97.68 , -55.779,  13.061],\n         [-97.68 , -54.779,  16.061],\n         ..., \n         [-99.68 , -68.779,  -9.939],\n         [-98.68 , -69.779,  -9.939],\n         [-98.68 , -69.779,  -9.939]],\n\n        [[-97.68 , -55.779,  13.061],\n         [-96.68 , -54.779,  14.061],\n         [-96.68 , -53.779,  17.061],\n         ..., \n         [-98.68 , -67.779,  -8.939],\n         [-97.68 , -68.779,  -8.939],\n         [-98.68 , -69.779,  -9.939]],\n\n        ..., \n        [[-60.68 , -57.779, -55.939],\n         [-59.68 , -56.779, -54.939],\n         [-60.68 , -57.779, -55.939],\n         ..., \n         [-70.68 , -67.779, -57.939],\n         [-68.68 , -66.779, -56.939],\n         [-67.68 , -65.779, -55.939]],\n\n        [[-37.68 , -32.779, -31.939],\n         [-32.68 , -27.779, -26.939],\n         [-31.68 , -26.779, -25.939],\n         ..., \n         [-72.68 , -69.779, -59.939],\n         [-72.68 , -70.779, -61.939],\n         [-72.68 , -70.779, -61.939]],\n\n        [[-23.68 , -18.779, -17.939],\n         [-24.68 , -19.779, -18.939],\n         [-36.68 , -31.779, -30.939],\n         ..., \n         [-73.68 , -69.779, -61.939],\n         [-74.68 , -72.779, -63.939],\n         [-76.68 , -74.779, -65.939]]]])]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "model.input.assign(content_image)\n",
    "\n",
    "out = model.output\n",
    "\n",
    "sess.run(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
